{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sandbox - Collect population.json.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOE4YXOsFkcaMh2zuTBJIVI"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"78T9EYRX6ZQm"},"source":["## Connect to Drive"]},{"cell_type":"code","metadata":{"id":"qzRTrhJCCTw_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609917100321,"user_tz":480,"elapsed":20600,"user":{"displayName":"Francisco Avalos Jr.","photoUrl":"","userId":"05379740764794418234"}},"outputId":"b2d37167-a49d-4d62-859f-bdb5068630a4"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LKNRy4BLCeGv","executionInfo":{"status":"ok","timestamp":1609917102871,"user_tz":480,"elapsed":1335,"user":{"displayName":"Francisco Avalos Jr.","photoUrl":"","userId":"05379740764794418234"}}},"source":["import os\n","import pandas as pd\n","import requests\n","import re\n","import numpy as np\n","import json\n","\n","from zipfile import ZipFile\n","# from keplergl import KeplerGl\n","from datetime import date, datetime, timedelta\n","from bs4 import BeautifulSoup\n","\n","pd.set_option('display.max_columns', 100)\n","pd.set_option('display.max_rows', 100)"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LAmQ7PY4FPL4"},"source":["### Collect Monthly POI from SafeGraph"]},{"cell_type":"code","metadata":{"id":"MaELYGCqJ_5k"},"source":["# os.chdir('/content/drive/My Drive/safegraph_data/safegraph_monthly_data/')\n","# files = ['patterns-part1.csv.gz','patterns-part2.csv.gz',\n","#          'patterns-part3.csv.gz','patterns-part4.csv.gz']\n","# prior_month_df = []\n","# for f in files:\n","#   prior_month_df.append(pd.read_csv(f, compression='gzip'))\n","# PRIOR_MONTH_DF = pd.concat(prior_month_df)\n","# del files, prior_month_df\n","# PRIOR_MONTH_DF = PRIOR_MONTH_DF[PRIOR_MONTH_DF['region']=='CA'] # 508,974"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d_ZNd7HufysR"},"source":["## Sample for LA here"]},{"cell_type":"code","metadata":{"id":"oEUnVse8fslz"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E-gijFg9FhdE"},"source":["## Collect LA County Communities (from Los Angeles Almanac)"]},{"cell_type":"code","metadata":{"id":"gQpM1TCDFmVd"},"source":["url = 'http://www.laalmanac.com/communications/cm02_communities.php'\n","req = requests.get(url)\n","soup = BeautifulSoup(req.text, 'html.parser')\n","td_data = soup.find_all('td')\n","\n","\n","# Extract comminity and zip code data\n","communities = {}\n","zipcodes = {}\n","c = 1\n","for index in range(len(td_data)):\n","    if (c % 2) != 0:\n","        community = td_data[index].text.strip()\n","        idx = int(index/2)\n","        communities[idx] = community\n","    if (c % 2) != 0:\n","        zip_code = td_data[index+1].text.strip()\n","        idx = int(index/2)\n","        zipcodes[idx] = zip_code\n","    c+=1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mvthadGzFpSR"},"source":["la_communities_n_zip = []\n","cities = []\n","cities_zips = []\n","# cities_zips_df = []\n","\n","\n","for i in zipcodes:\n","    la_communities_n_zip.append(communities[i] + '---' + zipcodes[i])\n","\n","\n","for i in la_communities_n_zip:\n","    city = i.split('---')[0]\n","    # Below currently in use\n","    item = re.sub(r\"(^Los.Angeles.|\\(Los Angeles\\)|PO Boxes|\\/.*)\", \"\", city.strip())\n","    \n","    item = re.sub(r\"(^Pasadena.*)\", \"Pasadena\", item)\n","    item = re.sub(r\"(^Alhambra.*)\", \"Alhambra\", item)\n","    item = re.sub(r\"(^Downtown.*)\", \"Downtown\", item)\n","    item = re.sub(r\"(.*Long Beach.*)\", \"Long Beach\", item)\n","    item = re.sub(r\"(Santa Clarita )\", \"\", item)\n","\n","    # FA\n","    item = re.sub(r\"(Rancho Dominguez.*)\", \"West Rancho Dominguez\", item) # Officially 'West Rancho Dominguez'\n","    item = re.sub(r\"(Los Angeles International Airport.*)\", \"Los Angeles\", item) # ME: get's 'Los Angeles' \n","    \n","    item = re.sub(r\"(\\(|\\))\", \"\", item.strip())\n","    \n","    # FA\n","    item = re.sub(r\" $\",\"\", item)\n","    \n","    cities.append(item)\n","    \n","    zipcode = i.split('---')[1]\n","    cities_zips.append(zipcode)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_yUkKyI6FpCc"},"source":["values = list()\n","value_set = set()\n","for key, val in communities.items():\n","    # Below currently in use\n","    item = re.sub(r\"(^Los.Angeles.|\\(Los Angeles\\)|PO Boxes|\\/.*)\", \"\", val.strip())\n","    \n","    item = re.sub(r\"(^Pasadena.*)\", \"Pasadena\", item)\n","    item = re.sub(r\"(^Alhambra.*)\", \"Alhambra\", item)\n","    item = re.sub(r\"(^Downtown.*)\", \"Downtown\", item)\n","    item = re.sub(r\"(.*Long Beach.*)\", \"Long Beach\", item)\n","    item = re.sub(r\"(Santa Clarita )\", \"\", item)\n","\n","    # these are mine\n","    item = re.sub(r\"(Rancho Dominguez.*)\", \"West Rancho Dominguez\", item) # Officially 'West Rancho Dominguez'\n","    item = re.sub(r\"(Los Angeles International Airport.*)\", \"Los Angeles\", item) # ME: get's 'Los Angeles' \n","    \n","    item = re.sub(r\"(\\(|\\))\", \"\", item.strip())\n","    \n","    # this is mine\n","    item = re.sub(r\" $\",\"\", item)\n","    \n","    values.append(item)\n","\n","values = set(values)\n","values = list(values)\n","LA_communities_df = pd.DataFrame(values)\n","LA_communities_df.columns = ['city']\n","del values"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mc_is9xqdCLt"},"source":["## Collect SafeGraph Points of Interest Data (Time independent)"]},{"cell_type":"code","metadata":{"id":"jWL5Tl6hdKj5"},"source":["# os.chdir('/content/drive/My Drive/safegraph_data/SafeGraph_POI_Data/')\n","\n","# filename = 'Archive.zip'\n","# poi = []\n","\n","# with ZipFile(filename, 'r') as zip:\n","#   with zip.open('core_poi-part1.csv.gz') as myfile:\n","#     poi.append(pd.read_csv(myfile, compression='gzip'))\n","#   with zip.open('core_poi-part2.csv.gz') as myfile:\n","#     poi.append(pd.read_csv(myfile, compression='gzip'))\n","#   with zip.open('core_poi-part3.csv.gz') as myfile:\n","#     poi.append(pd.read_csv(myfile, compression='gzip'))\n","#   with zip.open('core_poi-part4.csv.gz') as myfile:\n","#     poi.append(pd.read_csv(myfile, compression='gzip'))\n","#   with zip.open('core_poi-part5.csv.gz') as myfile:\n","#     poi.append(pd.read_csv(myfile, compression='gzip'))\n","\n","# poi_df = pd.concat(poi)\n","# del poi\n","\n","# POI_DF = poi_df[poi_df['region']=='CA']\n","\n","# la_poi = pd.merge(POI_DF, LA_communities_df, on='city', how='inner')\n","\n","# os.chdir('/content/drive/My Drive/safegraph_data/')\n","# la_poi.to_csv('la_poi.csv')\n","\n","# os.chdir('/content/drive/My Drive/safegraph_data/safegraph_monthly_data/')\n","\n","# del poi_df, POI_DF\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HFLfGU9OwK9I"},"source":["## Refine prior month data to LA only"]},{"cell_type":"code","metadata":{"id":"JwRUdnbLGITv"},"source":["PRIOR_MONTH_DF = pd.merge(PRIOR_MONTH_DF, LA_communities_df, on='city', how='inner')\n","# PRIOR_MONTH_DF.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"af1uirSrwGvj"},"source":["## Average Function"]},{"cell_type":"code","metadata":{"id":"YF6n1hMOXXFO"},"source":["def get_daily_average_for_a_month(data_input):\n","  \"\"\"\n","  Input: dataframe\n","  Output: list\n","  Function returns the daily average number of visiits to a particular point of \n","    interest for a given month.\n","  \"\"\"\n","  vday = data_input['visits_by_day']\n","  vday = pd.DataFrame(vday)\n","  average_list = []\n","  vday['visits_by_day'] = vday['visits_by_day'].str.split(',')\n","\n","  for i in vday['visits_by_day']:\n","    mylist = []\n","    for x in i:\n","      x = re.sub(\"^\\[\", \"\", x)\n","      x = re.sub(\"\\]$\", \"\", x)\n","      # x = x.replace('[', '')\n","      # x = x.replace(']', '')\n","      mylist.append(x)\n","    mylist = list(map(int, mylist))\n","    numerator = sum(mylist)\n","    denominator = len(mylist)\n","    single_poi_average = numerator / denominator\n","    average_list.append(single_poi_average)\n","  \n","  return average_list"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WLGXYIOFwiI_"},"source":["## Obtain average data and finalize file"]},{"cell_type":"code","metadata":{"id":"HjNv2xCLaLDr"},"source":["poi_daily_averages = get_daily_average_for_a_month(PRIOR_MONTH_DF)\n","PRIOR_MONTH_DF['average_pop'] = poi_daily_averages\n","\n","# PRIOR_MONTH_DF.sort_values('average_pop', ascending=False).head(3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ETpejuRHq9Rp"},"source":["population_df = PRIOR_MONTH_DF[['location_name', 'average_pop']].sort_values('average_pop', ascending=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X_-yoFeOq_gB"},"source":["population_df['average_pop'] = np.ceil(population_df['average_pop'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ixE3hbDUjlSH"},"source":["population_dict_1 = {}\n","for i in population_df.values:\n","  population_dict_1[i[0]] = i[1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k1So-NdQjnF8"},"source":["population_dict_final = {}\n","# count = 1\n","for key, val in population_dict_1.items():\n","  # new_key = key + '--()'\n","  # new_key = key + f'--(Region:{count})'\n","  new_key = key\n","  val = int(val)\n","  # population_dict_final[new_key] = str(val)\n","  population_dict_final[new_key] = val\n","  # count+=1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cqE5ePesk-ZW"},"source":["json = json.dumps(population_dict_final)\n","f = open('POI_population.json', \"w\")\n","f.write(json)\n","f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D7Y-Y6LpKvu6"},"source":["## If data already available for most recent month, then just pull directly "]},{"cell_type":"code","metadata":{"id":"Mm7ypgktKvat"},"source":["# os.chdir('/content/drive/My Drive/safegraph_data/safegraph_monthly_data/')\n","\n","# single_poi_export = {}\n","# POI = \"Temple Park Convalescent Hospital\"\n","\n","f = open('POI_population.json')\n","data = json.load(f)\n","\n","# for key, val in data.items():\n","#   if re.search(f'^{POI}', key):\n","#     single_poi_export[key] = val"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q6FW99rXNg63"},"source":["# os.chdir('/content/drive/My Drive/safegraph_data/SINGLE_POI_SAMPLE')\n","\n","# with open('POI_population_sample.json', 'w') as json_file:\n","#   json.dump(single_poi_export, json_file)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QvoZryE6ZU5f"},"source":["## Final files produced here\n","\n","* POI_population.json\n","* la_poi.csv"]},{"cell_type":"code","metadata":{"id":"XgF5kY8Kc1Qu"},"source":["# population_df['average_pop'].sum()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9TfslppWhWAD"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cMfdKSiWhiTq"},"source":["### Retreive saved files\n"]},{"cell_type":"code","metadata":{"id":"z3rcDOvnhnaX","executionInfo":{"status":"ok","timestamp":1609917138802,"user_tz":480,"elapsed":1301,"user":{"displayName":"Francisco Avalos Jr.","photoUrl":"","userId":"05379740764794418234"}}},"source":["os.chdir('/content/drive/My Drive/safegraph_data/safegraph_monthly_data/')\n","f = open('POI_population.json')\n","population_dict_final = json.load(f)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"7koI52TSiJcK","executionInfo":{"status":"ok","timestamp":1609917145192,"user_tz":480,"elapsed":3462,"user":{"displayName":"Francisco Avalos Jr.","photoUrl":"","userId":"05379740764794418234"}}},"source":["os.chdir('/content/drive/My Drive/safegraph_data/')\n","\n","la_poi = pd.read_csv('la_poi.csv')"],"execution_count":5,"outputs":[]}]}